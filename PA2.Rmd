---
title: "Title: Your document should have a title that briefly summarizes your data analysis"
output: 
  html_document:
    keep_md: true
---
# Synopsis

# Data Processing

## Loading libraries
Loading libraries that will be used later. The rubric specifically says to show all code, so echo will be left on.Tempting to use suppressPackageStartupMessages(expr)
```{r }
require(data.table)
require(lubridate)
require(dplyr)
require(ggplot2)
```

## Loading the data
```{r }

fname<-"repdata-data-StormData.csv.bz2"
if (!file.exists(fname)){
        message(paste("Cannot find",fname,"in local directory, downloading it..."))
        setInternet2(TRUE)  # set R_WIN_INTERNET2 to TRUE so https is supported in knitr (see http://stackoverflow.com/questions/19890633/r-produces-unsupported-url-scheme-error-when-getting-data-from-https-sites)
        download.file("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2",fname)

  
} else {
        message(paste("Found ",fname,"in local directory, reusing it..."))
}
```

The source file was first downloaded on Tue Aug 18 2015 with MD5 hash df4aa61fff89427db6b7f7b1113b5553 (generated by Microsoft's File Checksum Integrity Verifier version 2.05).

Reading in the source file takes a long time, so the read is cached.
```{r cache=TRUE}

# load("data.no.remarks.RData")
ptm <- proc.time()
df<-read.csv("repdata_data_StormData.csv.bz2")
proc.time() - ptm

```

```{r}
clean_data<-df %>% mutate(year=year(mdy_hms(BGN_DATE))) %>%
        select(year,STATE,EVTYPE,FATALITIES:CROPDMGEXP,REFNUM)
str(clean_data)
```
# Results
